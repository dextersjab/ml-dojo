{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4307772b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Basic CV model trained on CIFAR10 (W&B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65425f1d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314db7bf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317c8b05",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc521c7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## W&B config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1dda6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972f7f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using W&B Sweeps to run hyperparemter optimisation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b16a4c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'loss',\n",
    "        'goal': 'minimize'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1466f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # fixed\n",
    "    'batch_size': {\n",
    "        'value': 2\n",
    "    },\n",
    "    'momentum': {\n",
    "        'value': .9\n",
    "    },\n",
    "\n",
    "    # variable\n",
    "    'epochs': {\n",
    "        'values': [1, 2, 4, 8],\n",
    "    },\n",
    "    'lr': {\n",
    "        'values': [0.00001, .0001, .001],\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd'],\n",
    "    },\n",
    "    'fc_layer_1_size': {\n",
    "        'values': [60, 120, 180],\n",
    "    },\n",
    "    'fc_layer_2_size': {\n",
    "        'values': [42, 84, 126],\n",
    "    },\n",
    "    'dropout': {\n",
    "        'values': [0, .2, .4],\n",
    "    }\n",
    "}\n",
    "sweep_config['parameters'] = parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4d5a4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project='wandb201')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb96351",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42db7c20",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, fc_layer_1_size, fc_layer_2_size):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, fc_layer_1_size)\n",
    "        self.fc2 = nn.Linear(fc_layer_1_size, fc_layer_2_size)\n",
    "        self.fc3 = nn.Linear(fc_layer_2_size, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "def get_predictions(model, inputs, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    return model(inputs)\n",
    "\n",
    "def update_model(model, data, loss_fn, optimizer):\n",
    "    inputs, labels = data\n",
    "    predictions = get_predictions(model, inputs, optimizer)\n",
    "    loss = loss_fn(predictions, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def get_transforms(mean, std):\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "def fetch_data(transform):\n",
    "    return torchvision.datasets.CIFAR10(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "def get_data_wo_transform():\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    return fetch_data(transform)\n",
    "\n",
    "def get_data(transforms, batch_size=4):\n",
    "    trainset = fetch_data(transforms)\n",
    "    return torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "def calculate_mean_std(dataset):\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for data, _ in dataloader:\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_squared_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47930909",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Configurable hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2b0c2f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_optimizer(model, optimizer, learning_rate, momentum):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            momentum=momentum\n",
    "        )\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate\n",
    "        )\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d91c9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605128f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # create a W&B run w/ `wandb.init()`\n",
    "    with wandb.init(project='wandb201', config=None):\n",
    "        config = wandb.config\n",
    "        \n",
    "        # setup\n",
    "        mean, std = calculate_mean_std(get_data_wo_transform())\n",
    "        transforms = get_transforms(mean, std)\n",
    "        data = get_data(transforms, config.batch_size)\n",
    "        model = Net(\n",
    "            fc_layer_1_size=config.fc_layer_1_size,\n",
    "            fc_layer_2_size=config.fc_layer_2_size,\n",
    "        )\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = build_optimizer(\n",
    "            model,\n",
    "            config.optimizer,\n",
    "            config.lr,\n",
    "            config.momentum,\n",
    "        )\n",
    "\n",
    "        print('starting training run...')\n",
    "        # training\n",
    "        for epoch in range(config.epochs):\n",
    "            print(f'epoch: {epoch}')\n",
    "            for i, batch in enumerate(data):\n",
    "                loss = update_model(\n",
    "                    model,\n",
    "                    batch,\n",
    "                    loss_fn,\n",
    "                    optimizer,\n",
    "                )\n",
    "                wandb.log({'epoch': epoch, 'loss': loss})\n",
    "        print('finished training run')\n",
    "        path = './cifar_net.pth'\n",
    "        save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353350c3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train, project='wandb201')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}